agent02.resources=r1
agent02.channels=c1
agent02.sinks=k1 k2

agent02.sinkgroups=g1
agent02.sinkgroups.g1.sinks=k1 k2
agent02.sinkgroups.g1.processor.type=failover
agent02.sinkgroups.g1.processor.priority.k1=10
agent02.sinkgroups.g1.processor.priority.k2=5
agent02.sinkgroups.g1.processor.maxpenalty=10000

agent02.resources.r1.type=TAILDIR
agent02.resources.r1.positionFile=/home/hadoop/data/flume/agent02/position/taildir_position.json
agent02.resources.r1.fileHeader=true
agent02.resources.r1.filegroups=g1 g2
agent02.resources.r1.filegroups.g1=/home/hadoop/data/flume/agent02/data1/*.log
agent02.resources.r1.filegroups.g2=/home/hadoop/data/flume/agent02/data2/*.log

agent02.resources.r1.interceptors=i1 i2 i3
agent02.resources.r1.interceptors.i1.type=timestamp
agent02.resoruces.r1.interceptors.i1.preserveExisting=false
agent02.resources.r1.interceptors.i2.type=host
agent02.resources.r1.interceptors.i2.preserveExisting=true
agent02.resources.r1.interceptors.i2.useIP=true
agent02.resources.r1.interceptors.i2.hostHeader=host
agent02.resources.r1.interceptors.i3.type=static
agent02.resources.r1.interceptors.i3.key=logtype
agent02.resources.r1.interceptors.i3.value=clickflow
agent02.resources.r1.interceptors.i3.preserveExisting=true

agent02.resources.r1.channels=c1


agent02.channels.c1.type=memory
agent02.channels.c1.capacity=10000
agent02.channels.c1.transactionCapacity=1000

agent02.sinks.k1.type=avro
agent02.sinks.k1.hostname=hadoop02
agent02.sinks.k1.port=8001
agent02.sinks.k1.batch-size=1000
agent02.sinks.k1.compression-level=8

agent01.sinks.k2.type=avro
agent01.sinks.k2.hostname=hadoop02
agent01.sinks.k2.port=8002
agent01.sinks.k2.batch-size=1000
agent01.sinks.k2.compression-level=8


